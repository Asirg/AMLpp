{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\r\n",
    "import pandas as pd\r\n",
    "import pickle\r\n",
    "from AMLpp.transformers import *\r\n",
    "from AMLpp.conveyor import *\r\n",
    "from AMLpp.architect import *"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\analytic6\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\analytic6\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\r\n",
    "from sklearn.inspection import permutation_importance\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\r\n",
    "\r\n",
    "import sys\r\n",
    "sys.path.insert(0,'C:\\\\Users\\\\analytic6\\\\Desktop\\\\Work Space Analitic 6 (Asir)')\r\n",
    "sys.path.insert(0,'C:\\\\Users\\\\User\\\\Desktop\\\\work')\r\n",
    "\r\n",
    "from typing import List, Callable\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "from tpot import TPOTRegressor\r\n",
    "\r\n",
    "from datetime import datetime\r\n",
    "import pandas as pd\r\n",
    "import warnings\r\n",
    "import optuna\r\n",
    "import pickle\r\n",
    "import shap\r\n",
    "import time\r\n",
    "\r\n",
    "import tqdm \r\n",
    "\r\n",
    "##############################################################################\r\n",
    "class Conveyor:\r\n",
    "    \"\"\" Подобие sklearn.Pipeline, адаптированный под простоту и добавленный функционал\r\n",
    "\r\n",
    "    Parameters\r\n",
    "    ----------\r\n",
    "    *block : object\r\n",
    "        Объекты классов, что будут использоваться при обработке, и моделирование\r\n",
    "\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    ##############################################################################\r\n",
    "\r\n",
    "    def __init__(self, *blocks, estimator:object  = None, **params):\r\n",
    "        self.blocks = list(blocks)\r\n",
    "        self.estimator = estimator\r\n",
    "        # self.iter = 0\r\n",
    "        warnings.filterwarnings('ignore')\r\n",
    "        \r\n",
    "    def __repr__(self):\r\n",
    "        _repr = self.__class__.__name__ + \"= (\\n\"\r\n",
    "        indent = \" \" * (len(_repr) - 1)\r\n",
    "        for block in self.blocks:\r\n",
    "            _repr += f\"{indent}{repr(block)}, \\n\"\r\n",
    "        _repr += f\"{indent}estimator = {repr(self.estimator)}\"\r\n",
    "        _repr += f\"\\n{indent} )\"\r\n",
    "        return _repr\r\n",
    "\r\n",
    "    # def __next__(self):\r\n",
    "    #     if self.iter < len(self.blocks):\r\n",
    "    #         self.iter +=1 \r\n",
    "    #         return self.block[iter]\r\n",
    "    #     else:\r\n",
    "    #         self.iter = 0\r\n",
    "    #         return StopIteration\r\n",
    "\r\n",
    "    # def __getitem__(self, key):\r\n",
    "    #     if isinstance(key, slice):\r\n",
    "    #         return self.__class__(self.blocks[key])\r\n",
    "    #     else:\r\n",
    "    #         return self.blocks[key]\r\n",
    "    ##############################################################################\r\n",
    "\r\n",
    "    # @lead_time\r\n",
    "    def fit(self, X:pd.DataFrame,\r\n",
    "                  Y:pd.DataFrame or pd.Series,\r\n",
    "                  feature_importances:str = False):\r\n",
    "        self._fit(X, Y)\r\n",
    "        if feature_importances:\r\n",
    "            self.feature_importances(X, Y, transform = False)\r\n",
    "\r\n",
    "    # @lead_time\r\n",
    "    def fit_transform(self, X:pd.DataFrame, Y:pd.DataFrame or pd.Series):\r\n",
    "        return self._fit(X, Y)\r\n",
    "\r\n",
    "    def _fit(self, X:pd.DataFrame, Y:pd.DataFrame or pd.Series):\r\n",
    "        X_, Y_  = (X.copy(), Y.copy())\r\n",
    "\r\n",
    "        pbar = tqdm.tqdm(self.blocks)\r\n",
    "        for block in pbar:\r\n",
    "            pbar.set_postfix({'transform': block.__class__.__name__})\r\n",
    "            block.fit(X_, Y_)\r\n",
    "            X_, Y_ = self._transform(block, X_, Y_)\r\n",
    "\r\n",
    "        pbar.set_postfix({'transform': self.estimator.__class__.__name__})\r\n",
    "        self.estimator.fit(X_, Y_)\r\n",
    "        pbar.close()\r\n",
    "        return X_, Y_\r\n",
    "    ##############################################################################\r\n",
    "\r\n",
    "    # @lead_time\r\n",
    "    def transform(self,\r\n",
    "                        X:pd.DataFrame,\r\n",
    "                        Y:pd.DataFrame or pd.Series = pd.DataFrame()):\r\n",
    "        X_, Y_  = (X.copy(), Y.copy())\r\n",
    "        for block in self.blocks:\r\n",
    "            X_, Y_ = self._transform(block, X_, Y_)\r\n",
    "        return X_, Y_\r\n",
    "\r\n",
    "    def _transform(self, \r\n",
    "                        block:Callable,\r\n",
    "                        X:pd.DataFrame,\r\n",
    "                        Y:pd.DataFrame or pd.Series = pd.DataFrame()):\r\n",
    "        X = block.transform(X)\r\n",
    "        if not Y.empty and 'target_transform' in dir(block):\r\n",
    "            Y = block.target_transform(Y)\r\n",
    "        return X, Y\r\n",
    "\r\n",
    "    ##############################################################################\r\n",
    "\r\n",
    "    # @lead_time\r\n",
    "    def predict(self, X:pd.DataFrame):\r\n",
    "        return self.estimator.predict(self.transform(X.copy())[0])\r\n",
    "\r\n",
    "    ##############################################################################\r\n",
    "    # @lead_time\r\n",
    "    def score(self,\r\n",
    "                X:pd.DataFrame,\r\n",
    "                Y:pd.DataFrame or pd.Series,\r\n",
    "                sklearn_function:List[str] = ['roc_auc_score', 'r2_score', 'accuracy_score'],\r\n",
    "                precision_function:List[Callable] = [],\r\n",
    "                _return:bool = False):\r\n",
    "        \"\"\"\r\n",
    "        X:pd.DataFrame,\r\n",
    "        Y:pd.DataFrame or pd.Series,\r\n",
    "        sklearn_function:List[str] = ['roc_auc_score', 'r2_score', 'accuracy_score'],\r\n",
    "        precision_function:List[Callable] = []\r\n",
    "        \"\"\"\r\n",
    "        X_, Y_ = self.transform(X.copy(), Y.copy())\r\n",
    "        result = self.estimator.predict(X_)\r\n",
    "        score = \"\"\r\n",
    "        for func in sklearn_function:\r\n",
    "            try:\r\n",
    "                exec('from sklearn.metrics import ' + func)\r\n",
    "                score += \"function - {} = {}\\n\".format(func, eval(\"{}(Y_, result)\".format(func)))\r\n",
    "            except Exception as e:\r\n",
    "                score += \"function - {} = ERROR: {}\\n\".format(func, e)\r\n",
    "        for func in precision_function:\r\n",
    "            try:\r\n",
    "                score = \"function - {} = {}\\n\".format(func.__name__, func(Y_, result))\r\n",
    "            except Exception as e:\r\n",
    "                score = \"function - {} = ERROR: {}\\n\".format(func.__name__, e)\r\n",
    "\r\n",
    "        if _return:\r\n",
    "            return score, result, Y_\r\n",
    "        else:\r\n",
    "            print(score)\r\n",
    "    # @lead_time\r\n",
    "    def feature_importances(self,\r\n",
    "                            X:pd.DataFrame,\r\n",
    "                            Y:pd.DataFrame or pd.Series, \r\n",
    "                            show:str = 'all', # all, sklearn, shap\r\n",
    "                            save:bool = True,\r\n",
    "                            name_plot:str = \"\",\r\n",
    "                            transform = True): \r\n",
    "                            \r\n",
    "        if transform:\r\n",
    "            X_, Y_ = self.transform(X.copy(), Y.copy())\r\n",
    "\r\n",
    "        if show == 'all' or show == 'shap':\r\n",
    "            try:\r\n",
    "                explainer = shap.Explainer(self.estimator)\r\n",
    "                shap_values = explainer(X_)\r\n",
    "                shap.plots.bar(shap_values[0], show = False)\r\n",
    "                if save:\r\n",
    "                    name_plot = name_plot if name_plot != \"\" else datetime.now().strftime(\"%Y-%m-%d_%M\")\r\n",
    "                    plt.savefig('{}_shap.jpeg'.format(name_plot), dpi = 150,  pad_inches=0)\r\n",
    "                plt.show()\r\n",
    "            except Exception as e:\r\n",
    "                print('shap plot - ERROR: ', e)\r\n",
    "\r\n",
    "        if show == \"all\" or show == \"sklearn\":\r\n",
    "            try:\r\n",
    "                result = permutation_importance(self.estimator, X_, Y_, n_repeats=2, random_state=42)\r\n",
    "                index = X_.columns if type(X_) == pd.DataFrame else X.columns\r\n",
    "                forest_importances = pd.Series(result.importances_mean, index=index)\r\n",
    "                fig, ax = plt.subplots(figsize=(20, 10))\r\n",
    "                forest_importances.plot.bar(yerr=result.importances_std, ax=ax)\r\n",
    "                ax.set_title(\"Feature importances using permutation on full model\")\r\n",
    "                ax.set_ylabel(\"Mean accuracy decrease\")\r\n",
    "                fig.tight_layout()\r\n",
    "                if save:\r\n",
    "                    name_plot = name_plot if name_plot != \"\" else datetime.now().strftime(\"%Y-%m-%d_%M\")\r\n",
    "                    plt.savefig('{}_sklearn.jpeg'.format(name_plot))\r\n",
    "                plt.show()\r\n",
    "            except Exception as e:\r\n",
    "                print('Sklearn plot - ERROR: ', e)\r\n",
    "    ##############################################################################\r\n",
    "    # @lead_time\r\n",
    "    def fit_model(self, \r\n",
    "                    X:pd.DataFrame, Y:pd.DataFrame or pd.Series,\r\n",
    "                    X_test:pd.DataFrame = None, Y_test:pd.DataFrame = None,\r\n",
    "                    type_model:str = 'regressor',\r\n",
    "                    export_model:str = \"default\",\r\n",
    "                    compare_model:bool = True,\r\n",
    "                    tpot_params:dict  = {\"generations\":5, \"population_size\":50, \"n_jobs\":-1},\r\n",
    "                    lgb_params:dict = {\"\"}, categorical_columns:List[str] = []\r\n",
    "                    ):\r\n",
    "\r\n",
    "\r\n",
    "        X_train, Y_train = self.fit_transform(X, Y)\r\n",
    "\r\n",
    "        if type(X_test) != type(None) and type(Y_test) != type(None):\r\n",
    "            X_test, Y_test = self.transform(X_test, Y_test)\r\n",
    "        else:\r\n",
    "            X_test, Y_test = X_train, Y_train\r\n",
    "            \r\n",
    "        print('start fit tpot model !!!!')\r\n",
    "        tpot_model, result = self.fit_model_tpot(X_train, Y_train, X_test, params = tpot_params)\r\n",
    "        tpot_score = r2_score(Y_test, result)\r\n",
    "        print(tpot_model,\"\\n\",f\"r2_score = {tpot_score}\")\r\n",
    "        time.sleep(1)\r\n",
    "        print('start fit lgb model !!!!')\r\n",
    "        lgb_model, result = self.fit_model_lgb(X_train, Y_train, X_test, Y_test, \r\n",
    "                                                categorical_columns = categorical_columns, params = lgb_params)\r\n",
    "        lgb_score = r2_score(Y_test, result)\r\n",
    "        print(lgb_model,\"\\n\",f\"r2_score = {lgb_score}\")\r\n",
    "\r\n",
    "        if tpot_score > lgb_score:\r\n",
    "            for step in tpot_model.steps[:-1]:\r\n",
    "                self.blocks.append(step)\r\n",
    "            self.estimator = tpot_model[-1]\r\n",
    "            print(\"BEST Conveyor: TPOT\")\r\n",
    "        else:\r\n",
    "            self.estimator = lgb_model\r\n",
    "            print(\"BEST Conveyor: LGB\")\r\n",
    "            \r\n",
    "        print(self)\r\n",
    "        if export_model != \"\":\r\n",
    "            if export_model == \"default\":\r\n",
    "                export_model = \"model_\" + datetime.now().strftime(\"%Y_%m_%d_m%M\")\r\n",
    "            with open(export_model, 'wb') as save_file:\r\n",
    "                pickle.dump(self, save_file)\r\n",
    "\r\n",
    "    def fit_model_tpot(self, X:pd.DataFrame, Y:pd.DataFrame, X_test:pd.DataFrame, params:dict = {}):\r\n",
    "        tpot = TPOTRegressor(**params, random_state=42).fit(X, Y)\r\n",
    "        make_pipe, import_libs = tpot.export('', get_pipeline=True)\r\n",
    "        exec(import_libs)\r\n",
    "        model = eval(make_pipe)\r\n",
    "        model = model if (type(model) == Pipeline) else make_pipeline(model)\r\n",
    "        return model.fit(X, Y), model.predict(X_test) if type(X_test) == pd.DataFrame else False\r\n",
    "\r\n",
    "    def fit_model_lgb(self, X:pd.DataFrame, Y:pd.DataFrame, \r\n",
    "                            X_test:pd.DataFrame, Y_test:pd.DataFrame, \r\n",
    "                            categorical_columns:List[str] = None, params:dict = {}):\r\n",
    "        study = optuna.create_study(direction='maximize')\r\n",
    "        study.optimize(LGBOptimizer(X, Y, X_test, Y_test, categorical_columns = categorical_columns, params = params),\r\n",
    "                                        n_trials=20,  n_jobs = -1, show_progress_bar = False)\r\n",
    "        model = LGBMRegressor(**study.best_params, random_state=42).fit(X, Y)\r\n",
    "        result = model.predict(X_test) if type(X_test) == pd.DataFrame else False \r\n",
    "        return model, result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "df = pd.read_excel('test.xlsx')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "with open('md', 'rb') as file:\r\n",
    "    model = pickle.load(file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "model.predict(df)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.45249465, 0.09739054, 0.15086373, 0.34822291, 0.38918459,\n",
       "       0.27881089, 0.24031694, 0.38197861, 0.36309543, 0.55304106,\n",
       "       0.3976984 , 0.41836881, 0.2212661 , 0.36586768, 0.27035211,\n",
       "       0.26615116, 0.1658414 , 0.46320552, 0.27565239, 0.3105457 ,\n",
       "       0.31541112, 0.42240632, 0.4198665 , 0.42279853, 0.5118134 ,\n",
       "       0.19770543, 0.44022177, 0.30749668, 0.27824571, 0.17241294,\n",
       "       0.31775187, 0.28507006, 0.39403543, 0.40686464, 0.28805151,\n",
       "       0.21294191, 0.29536586, 0.52721519, 0.43334288, 0.28607696,\n",
       "       0.5152715 , 0.50611041, 0.20164979, 0.24857929, 0.41115293,\n",
       "       0.25697274, 0.41653331, 0.34451173, 0.37841614, 0.18905118,\n",
       "       0.546391  , 0.37367631, 0.55311641, 0.23859054, 0.42908631,\n",
       "       0.52237161, 0.353179  , 0.37153335, 0.27724309, 0.41897879,\n",
       "       0.17754016, 0.47659073, 0.25070869, 0.19272131, 0.47896952,\n",
       "       0.36289466, 0.56824345, 0.45954006, 0.46894267, 0.57494003,\n",
       "       0.42530684, 0.46868302, 0.25813322, 0.29458029, 0.49339193,\n",
       "       0.39131484, 0.33170331, 0.27824992, 0.36980909, 0.16669338,\n",
       "       0.30071749, 0.09868443, 0.27687419, 0.23955152, 0.24618803,\n",
       "       0.20860434, 0.18715594, 0.15021462, 0.14654768, 0.09926365,\n",
       "       0.15270262, 0.14576725, 0.11439959, 0.10646398, 0.35905851,\n",
       "       0.11138781, 0.09990475, 0.1146765 , 0.23009101, 0.23616521,\n",
       "       0.63313063, 0.74165881, 0.77834377, 0.76274633, 0.58376856,\n",
       "       0.80608414, 0.58090049, 0.81985654, 0.64703655, 0.77931542,\n",
       "       0.56061034, 0.71342208, 0.66546081, 0.65858148, 0.55921909,\n",
       "       0.80387885, 0.78117626, 0.70865292, 0.618116  , 0.450402  ,\n",
       "       0.57599766, 0.80540019, 0.88698948, 0.68863316, 0.77739691,\n",
       "       0.79919613, 0.75570509, 0.64002446, 0.50159198, 0.79530956,\n",
       "       0.58990798, 0.78190391, 0.69293535, 0.61678445, 0.70948315,\n",
       "       0.77941734, 0.69104962, 0.77151886, 0.79909174, 0.74501932,\n",
       "       0.87285613, 0.61254916, 0.50165867, 0.70762831, 0.68822115,\n",
       "       0.83042138, 0.60238455, 0.80195015, 0.61831553, 0.59866772,\n",
       "       0.69043645, 0.52099235, 0.44425489, 0.79969408, 0.59194718,\n",
       "       0.68827335, 0.54739183, 0.46252679, 0.32620727, 0.68475895,\n",
       "       0.69479496, 0.81246624, 0.7376033 , 0.77745086, 0.63438554,\n",
       "       0.68426283, 0.7272043 , 0.64704843, 0.75893863, 0.69833772,\n",
       "       0.66816921, 0.60643282, 0.76556764, 0.65482252, 0.56791546,\n",
       "       0.82250535, 0.74521107, 0.2519938 , 0.65124003, 0.81849243,\n",
       "       0.61331188, 0.51264524, 0.58491123, 0.56891595, 0.66731782,\n",
       "       0.69745125, 0.64738912, 0.61551399, 0.76570012, 0.60586128,\n",
       "       0.69372687, 0.68303934, 0.50565453, 0.68446561, 0.72506751,\n",
       "       0.73883366, 0.54663374, 0.67221478, 0.63859582, 0.44956284])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "xx = model.blocks[0].transform(df)\r\n",
    "print(df['user_agent'])\r\n",
    "xx['system']"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0     Mozilla/5.0 (Linux; Android 10; M2006C3MNG) Ap...\n",
      "1     Mozilla/5.0 (Linux; Android 10; M2006C3MNG) Ap...\n",
      "2     Mozilla/5.0 (Linux; Android 10; M2006C3MNG) Ap...\n",
      "3     Mozilla/5.0 (Linux; Android 10; SM-A315F) Appl...\n",
      "4     Mozilla/5.0 (Linux; Android 8.0.0; SM-G930F) A...\n",
      "                            ...                        \n",
      "95    Mozilla/5.0 (Linux; Android 5.0.2; LG-LS980) A...\n",
      "96    Mozilla/5.0 (Linux; Android 6.0; HT37) AppleWe...\n",
      "97    Mozilla/5.0 (Linux; Android 7.1.2; Redmi Note ...\n",
      "98    Mozilla/5.0 (Linux; Android 9; TECNO LC6a) App...\n",
      "99    Mozilla/5.0 (Linux; Android 9; TECNO LC6a) App...\n",
      "Name: user_agent, Length: 100, dtype: object\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    NaN\n",
       "2    NaN\n",
       "3    NaN\n",
       "4    NaN\n",
       "      ..\n",
       "95   NaN\n",
       "96   NaN\n",
       "97   NaN\n",
       "98   NaN\n",
       "99   NaN\n",
       "Name: system, Length: 100, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "x = model.transform(df)[0]\r\n",
    "x['email']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0     6.0\n",
       "1     6.0\n",
       "2     6.0\n",
       "3     1.0\n",
       "4     1.0\n",
       "     ... \n",
       "95    1.0\n",
       "96    1.0\n",
       "97    1.0\n",
       "98    1.0\n",
       "99    1.0\n",
       "Name: email, Length: 100, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3a56291688fe74fff73a1fbf6b0dc2a5cfa3a0985083944054e17fe03253671"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}