{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(\r\n",
    "    {'fea1':[0,0,0,2,2,2,1,1,1],\r\n",
    "     'fea2':['a',np.nan,'b','b','b','b',np.nan,'c','c'],\r\n",
    "     'fea3':['Магазин','Магазин1','Магази','Что','ЧТОт','ЧТК','ЧАШК','ЧАШКК','чаш']})\r\n",
    "Y = pd.DataFrame({'target':[1,1,1,1,0,1,0,0,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fea1</th>\n",
       "      <th>fea2</th>\n",
       "      <th>fea3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>Магазин</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Магазин1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "      <td>Магази</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>Что</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>ЧТОт</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>ЧТК</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ЧАШК</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>ЧАШКК</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>чаш</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fea1 fea2      fea3\n",
       "0     0    a   Магазин\n",
       "1     0  NaN  Магазин1\n",
       "2     0    b    Магази\n",
       "3     2    b       Что\n",
       "4     2    b      ЧТОт\n",
       "5     2    b       ЧТК\n",
       "6     1  NaN      ЧАШК\n",
       "7     1    c     ЧАШКК\n",
       "8     1    c       чаш"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model.сonveyor import *\r\n",
    "from sklearn.preprocessing import OrdinalEncoder\r\n",
    "from typing import List\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "####################################################################################################\r\n",
    "class Column_scaler:\r\n",
    "    \"\"\"\r\n",
    "    Pipeline of transforms with a final estimator.\r\n",
    "\r\n",
    "    Sequentially apply a list of transforms and a final estimator.\r\n",
    "    Intermediate steps of the pipeline must be 'transforms', that is, they\r\n",
    "    must implement fit and transform methods.\r\n",
    "    The final estimator only needs to implement fit.\r\n",
    "    The transformers in the pipeline can be cached using ``memory`` argument.\r\n",
    "\r\n",
    "    The purpose of the pipeline is to assemble several steps that can be\r\n",
    "    cross-validated together while setting different parameters.\r\n",
    "    For this, it enables setting parameters of the various steps using their\r\n",
    "    names and the parameter name separated by a '__', as in the example below.\r\n",
    "    A step's estimator may be replaced entirely by setting the parameter\r\n",
    "    with its name to another estimator, or a transformer removed by setting\r\n",
    "    it to 'passthrough' or ``None``.\r\n",
    "\r\n",
    "    Read more in the :ref:`User Guide <pipeline>`.\r\n",
    "\r\n",
    "    .. versionadded:: 0.5\r\n",
    "\r\n",
    "    Parameters\r\n",
    "    ----------\r\n",
    "    steps : list\r\n",
    "        List of (name, transform) tuples (implementing fit/transform) that are\r\n",
    "        chained, in the order in which they are chained, with the last object\r\n",
    "        an estimator.\r\n",
    "\r\n",
    "    memory : str or object with the joblib.Memory interface, default=None\r\n",
    "        Used to cache the fitted transformers of the pipeline. By default,\r\n",
    "        no caching is performed. If a string is given, it is the path to\r\n",
    "        the caching directory. Enabling caching triggers a clone of\r\n",
    "        the transformers before fitting. Therefore, the transformer\r\n",
    "        instance given to the pipeline cannot be inspected\r\n",
    "        directly. Use the attribute ``named_steps`` or ``steps`` to\r\n",
    "        inspect estimators within the pipeline. Caching the\r\n",
    "        transformers is advantageous when fitting is time consuming.\r\n",
    "\r\n",
    "    verbose : bool, default=False\r\n",
    "        If True, the time elapsed while fitting each step will be printed as it\r\n",
    "        is completed.\r\n",
    "\r\n",
    "    Attributes\r\n",
    "    ----------\r\n",
    "    named_steps : :class:`~sklearn.utils.Bunch`\r\n",
    "        Dictionary-like object, with the following attributes.\r\n",
    "        Read-only attribute to access any step parameter by user given name.\r\n",
    "        Keys are step names and values are steps parameters.\r\n",
    "\r\n",
    "    See Also\r\n",
    "    --------\r\n",
    "    make_pipeline : Convenience function for simplified pipeline construction.\r\n",
    "\r\n",
    "    Examples\r\n",
    "    --------\r\n",
    "    >>> from sklearn.svm import SVC\r\n",
    "    >>> from sklearn.preprocessing import StandardScaler\r\n",
    "    >>> from sklearn.datasets import make_classification\r\n",
    "    >>> from sklearn.model_selection import train_test_split\r\n",
    "    >>> from sklearn.pipeline import Pipeline\r\n",
    "    >>> X, y = make_classification(random_state=0)\r\n",
    "    >>> X_train, X_test, y_train, y_test = train_test_split(X, y,\r\n",
    "    ...                                                     random_state=0)\r\n",
    "    >>> pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC())])\r\n",
    "    >>> # The pipeline can be used as any other estimator\r\n",
    "    >>> # and avoids leaking the test set into the train set\r\n",
    "    >>> pipe.fit(X_train, y_train)\r\n",
    "    Pipeline(steps=[('scaler', StandardScaler()), ('svc', SVC())])\r\n",
    "    >>> pipe.score(X_test, y_test)\r\n",
    "    0.88\r\n",
    "    \"\"\"\r\n",
    "    ordinal_scaler = {}\r\n",
    "    means_scaler = {}\r\n",
    "\r\n",
    "    def __init__(self, columns_to_ordinal, columns_to_int):\r\n",
    "        self.columns_to_ordinal = columns_to_ordinal\r\n",
    "        self.columns_to_int = columns_to_int\r\n",
    "\r\n",
    "    ## Выборка слов из датасета, и подача их на вход \r\n",
    "    def fit(self, X:pd.DataFrame, y:pd.Series):\r\n",
    "        \"\"\"Fit the model and transform with the final estimator\r\n",
    "\r\n",
    "        Fits all the transforms one after the other and transforms the\r\n",
    "        data, then uses fit_transform on transformed data with the final\r\n",
    "        estimator.\r\n",
    "\r\n",
    "        Parameters\r\n",
    "        ----------\r\n",
    "        X : iterable\r\n",
    "            Training data. Must fulfill input requirements of first step of the\r\n",
    "            pipeline.\r\n",
    "\r\n",
    "        y : iterable, default=None\r\n",
    "            Training targets. Must fulfill label requirements for all steps of\r\n",
    "            the pipeline.\r\n",
    "\r\n",
    "        **fit_params : dict of string -> object\r\n",
    "            Parameters passed to the ``fit`` method of each step, where\r\n",
    "            each parameter name is prefixed such that parameter ``p`` for step\r\n",
    "            ``s`` has key ``s__p``.\r\n",
    "\r\n",
    "        Returns\r\n",
    "        -------\r\n",
    "        Xt : array-like of shape  (n_samples, n_transformed_features)\r\n",
    "            Transformed samples\r\n",
    "        \"\"\"\r\n",
    "        for column in self.columns_to_ordinal:\r\n",
    "            self.ordinal_scaler[column] = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan)\r\n",
    "            self.ordinal_scaler[column].fit(X[column].to_frame().fillna('NAN').astype(str))\r\n",
    "            ordinal_code = self.to_ordinal_scaler(X[column])\r\n",
    "            self.means_scaler[column] = np.mean(ordinal_code[~np.isnan(ordinal_code)])\r\n",
    "            \r\n",
    "        for column in self.columns_to_int:\r\n",
    "            self.means_scaler[column] = float(X[column].loc[~X[column].isnull()].mean())\r\n",
    "\r\n",
    "\r\n",
    "        if not os.path.exists('model_new_property'):\r\n",
    "            os.makedirs('model_new_property')\r\n",
    "        with open('model_new_property/means_scaler', 'wb') as file:\r\n",
    "            pickle.dump(self.means_scaler,file)\r\n",
    "        with open('model_new_property/ordinal_scaler', 'wb') as file:\r\n",
    "            pickle.dump(self.ordinal_scaler,file)\r\n",
    "        return self\r\n",
    "\r\n",
    "    def transform(self, X:pd.DataFrame, y = None)->pd.Series:\r\n",
    "        with open('model_new_property/means_scaler', 'rb') as file:\r\n",
    "            self.means_scaler = pickle.load(file)\r\n",
    "        with open('model_new_property/ordinal_scaler', 'rb') as file:\r\n",
    "            self.ordinal_scaler = pickle.load(file)\r\n",
    "\r\n",
    "        for column in self.columns_to_ordinal:\r\n",
    "            X[column] = self.to_ordinal_scaler(X[column])\r\n",
    "            X[column].loc[X[column].isnull()] = self.means_scaler[column]\r\n",
    "            \r\n",
    "        for column in self.columns_to_int:\r\n",
    "            X[column] = self.to_int_with_mean(X[column])\r\n",
    "            X[column].loc[X[column].isnull()] = self.means_scaler[column]\r\n",
    "\r\n",
    "        for column in X:\r\n",
    "            X[column].loc[X[column].isnull()] = 0\r\n",
    "        X['purpose_other'] =  X['purpose_other'].astype(str)\r\n",
    "        return X\r\n",
    "        \r\n",
    "\r\n",
    "    def to_ordinal_scaler(self, series: pd.Series) -> pd.Series:\r\n",
    "        frame = series.to_frame().fillna('NAN')\r\n",
    "        frame = series.astype(str)\r\n",
    "        return self.ordinal_scaler[series.name].transform(frame.values.reshape(-1,1))\r\n",
    "\r\n",
    "    def to_int_with_mean(self, series: pd.Series) -> pd.Series:\r\n",
    "        try:\r\n",
    "            series = series.fillna(self.means_scaler[series.name])\r\n",
    "            series = series.astype(int)\r\n",
    "        except Exception as e:\r\n",
    "            series = series.fillna(0)\r\n",
    "            series = series.astype(int)\r\n",
    "        return series\r\n",
    "############################################################################################################\r\n",
    "\r\n",
    "class Conveyor:\r\n",
    "    def __init__(self, *blocks, **params):\r\n",
    "        print(\"__init__\")\r\n",
    "        self.blocks = list(blocks)\r\n",
    "        pass\r\n",
    "\r\n",
    "    def train(self, X:pd.DataFrame, Y:pd.DataFrame or pd.Series):\r\n",
    "        X_, Y_  = ( X.copy(), Y.copy() )\r\n",
    "        for block in range(len(self.blocks)):\r\n",
    "            self.blocks[block].fit(X_, Y_)\r\n",
    "            self.blocks[block].transform(X_)\r\n",
    "\r\n",
    "    def predict(self, X:pd.DataFrame, Y:pd.DataFrame or pd.Series = None):\r\n",
    "        X_ =  X.copy() \r\n",
    "        for block in range(len(self.blocks)):\r\n",
    "            self.blocks[block].transform(X_)\r\n",
    "        print(X_)\r\n",
    "    def export(self):\r\n",
    "        pass\r\n",
    "\r\n",
    "def most_frequency(x:List[List[int]]):\r\n",
    "    x_ = [i[0] for i in x]\r\n",
    "    return np.argmax(np.bincount(x_))\r\n",
    "\r\n",
    "class CategoricalEncoder():\r\n",
    "    encoder = {}\r\n",
    "\r\n",
    "    def __init__(self, columns:pd.DataFrame, strategy:str='mean', fill_value:float or str = 0): # strategy in mean, median, most_frequency, const, iterative inputer?\r\n",
    "        self.columns = columns\r\n",
    "        self.fill_value = {'mean':np.mean, 'median':np.median, 'most_freq':most_frequency, 'const':(lambda x:fill_value)}\r\n",
    "        self.fill_value = self.fill_value[strategy]\r\n",
    "\r\n",
    "    def fit(self, X:pd.DataFrame, Y:pd.DataFrame or pd.Series):\r\n",
    "        for column in self.columns:\r\n",
    "            self.encoder[column] = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan)\r\n",
    "            X_fit = pd.DataFrame(X[column].loc[~X[column].isnull()])\r\n",
    "            self.encoder[column].fit(X_fit)\r\n",
    "            X_transform = self.encoder[column].transform(pd.DataFrame(X_fit))\r\n",
    "            self.encoder[column].unknown_value = self.fill_value(X_transform)\r\n",
    "        return self\r\n",
    "\r\n",
    "    def transform(self, X:pd.DataFrame):\r\n",
    "        for column in self.columns:\r\n",
    "            X[column] = self.encoder[column].transform(pd.DataFrame(X[column].fillna('NAN')))\r\n",
    "        pass\r\n",
    "\r\n",
    "class Imputer():\r\n",
    "    encoder = {}\r\n",
    "\r\n",
    "    def __init__(self, columns:pd.DataFrame, strategy:str='mean', fill_value:float or str = 0): # strategy in mean, median, most_frequency, const, iterative inputer?\r\n",
    "        self.columns = columns\r\n",
    "        self.fill_value = {'mean':np.mean, 'median':np.median, 'most_freq':most_frequency, 'const':(lambda x:fill_value)}\r\n",
    "        self.fill_value = self.fill_value[strategy]\r\n",
    "\r\n",
    "    def fit(self, X:pd.DataFrame, Y:pd.DataFrame or pd.Series):\r\n",
    "        for column in self.columns:\r\n",
    "            self.encoder[column] = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan)\r\n",
    "            X_fit = pd.DataFrame(X[column].loc[~X[column].isnull()])\r\n",
    "            self.encoder[column].fit(X_fit)\r\n",
    "            X_transform = self.encoder[column].transform(pd.DataFrame(X_fit))\r\n",
    "            self.encoder[column].unknown_value = self.fill_value(X_transform)\r\n",
    "        return self\r\n",
    "\r\n",
    "    def transform(self, X:pd.DataFrame):\r\n",
    "        for column in self.columns:\r\n",
    "            X[column] = self.encoder[column].transform(pd.DataFrame(X[column].fillna('NAN')))\r\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__\n"
     ]
    }
   ],
   "source": [
    "model = Conveyor(CategoricalEncoder(columns=['fea2','fea3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(\r\n",
    "    {'fea1':[0,0,1,2,5],\r\n",
    "     'fea2':['a',np.nan,'b',np.nan,'c'],\r\n",
    "     'fea3':['1','1','1','1','1']})\r\n",
    "Y_test = pd.DataFrame({'target':[1,1,1,1,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fea1      fea2  fea3\n",
      "0     0  0.000000   4.0\n",
      "1     0  1.142857   4.0\n",
      "2     1  1.000000   4.0\n",
      "3     2  1.142857   4.0\n",
      "4     5  2.000000   4.0\n"
     ]
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\r\n",
    "with open('model_', 'wb') as save_file:\r\n",
    "    pickle.dump(model, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_', 'rb') as load_file:\r\n",
    "    model_test = pickle.load(load_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Conveyor at 0x235c6ad4910>"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fea1      fea2  fea3\n",
      "0     0  0.000000   4.0\n",
      "1     0  1.142857   4.0\n",
      "2     1  1.000000   4.0\n",
      "3     2  1.142857   4.0\n",
      "4     5  2.000000   4.0\n"
     ]
    }
   ],
   "source": [
    "model_test.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}